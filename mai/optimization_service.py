"""
Service d'optimisation intelligente pour la Phase 6.
IntÃ¨gre tous les services existants pour une performance maximale.
"""
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from django.conf import settings
from django.utils import timezone
from mai.embedding_service import embedding_service
from mai.vector_search_service import vector_search_service
from mai.cache_service import cache_service as advanced_cache_service
from mai.vector_index_service import vector_index_service
from mai.monitoring_service import advanced_monitoring_service
from mai.models import DocumentEmbedding, RAGSearchLog

logger = logging.getLogger(__name__)

class IntelligentOptimizationService:
    """Service d'optimisation intelligente qui orchestre tous les services"""
    
    def __init__(self):
        self.optimization_config = self._load_optimization_config()
        self.performance_history = []
        self.optimization_schedule = []
        
    def _load_optimization_config(self) -> Dict[str, Any]:
        """Charge la configuration d'optimisation"""
        return {
            'auto_optimization': {
                'enabled': True,
                'interval_hours': 6,
                'performance_threshold': 0.8,
                'cache_warmup_enabled': True
            },
            'performance_targets': {
                'response_time_ms': 200,
                'cache_hit_rate': 0.85,
                'success_rate': 0.98,
                'throughput_qps': 50
            },
            'optimization_strategies': {
                'cache_optimization': True,
                'index_optimization': True,
                'embedding_optimization': True,
                'monitoring_optimization': True
            }
        }
    
    def run_comprehensive_optimization(self) -> Dict[str, Any]:
        """ExÃ©cute une optimisation complÃ¨te du systÃ¨me"""
        start_time = time.time()
        optimization_results = {}
        
        try:
            logger.info("ðŸš€ DÃ©marrage de l'optimisation complÃ¨te du systÃ¨me RAG")
            
            # 1. Optimisation du cache local (Redis dÃ©sactivÃ©)
            logger.info("ðŸ“¦ Optimisation du cache local (Redis dÃ©sactivÃ©)...")
            cache_result = self._optimize_cache()
            optimization_results['cache'] = cache_result
            
            # 2. Optimisation des index vectoriels
            logger.info("ðŸ” Optimisation des index vectoriels...")
            index_result = self._optimize_vector_indexes()
            optimization_results['indexes'] = index_result
            
            # 3. Optimisation des embeddings
            logger.info("ðŸ§  Optimisation des embeddings...")
            embedding_result = self._optimize_embeddings()
            optimization_results['embeddings'] = embedding_result
            
            # 4. Optimisation du monitoring
            logger.info("ðŸ“Š Optimisation du monitoring...")
            monitoring_result = self._optimize_monitoring()
            optimization_results['monitoring'] = monitoring_result
            
            # 5. PrÃ©chauffage intelligent
            logger.info("ðŸ”¥ PrÃ©chauffage intelligent du systÃ¨me...")
            warmup_result = self._intelligent_warmup()
            optimization_results['warmup'] = warmup_result
            
            # 6. Validation des performances
            logger.info("âœ… Validation des performances...")
            validation_result = self._validate_performance()
            optimization_results['validation'] = validation_result
            
            total_duration = time.time() - start_time
            
            # Enregistrer l'optimisation
            self._record_optimization(optimization_results, total_duration)
            
            return {
                'success': True,
                'duration_seconds': round(total_duration, 2),
                'optimization_results': optimization_results,
                'message': 'Optimisation complÃ¨te terminÃ©e avec succÃ¨s'
            }
            
        except Exception as e:
            logger.error(f"Erreur optimisation complÃ¨te: {e}")
            return {
                'success': False,
                'error': str(e),
                'duration_seconds': round(time.time() - start_time, 2)
            }
    
    def _optimize_cache(self) -> Dict[str, Any]:
        """Optimise le cache local (Redis dÃ©sactivÃ©)"""
        try:
            # 1. VÃ©rifier la santÃ© du cache local
            cache_health = advanced_cache_service.health_check()
            
            # 2. Optimiser le cache local si nÃ©cessaire
            if cache_health['status'] in ['warning', 'critical']:
                optimization_result = advanced_cache_service.optimize_cache()
            else:
                optimization_result = {'success': True, 'message': 'Cache local dÃ©jÃ  optimisÃ©'}
            
            # 3. PrÃ©chauffer le cache local (si mÃ©thode disponible)
            try:
                warmup_result = advanced_cache_service.warm_up_cache()
            except AttributeError:
                warmup_result = {'success': True, 'message': 'Warm-up non disponible pour cache local'}
            
            # 4. Obtenir les statistiques finales
            final_stats = advanced_cache_service.get_cache_stats()
            
            return {
                'health_before': cache_health,
                'optimization': optimization_result,
                'warmup': warmup_result,
                'final_stats': final_stats
            }
            
        except Exception as e:
            logger.error(f"Erreur optimisation cache: {e}")
            return {'error': str(e)}
    
    def _optimize_vector_indexes(self) -> Dict[str, Any]:
        """Optimise les index vectoriels"""
        try:
            # 1. Analyser les performances actuelles
            performance_analysis = vector_index_service.analyze_index_performance()
            
            # 2. VÃ©rifier si une reindexation est nÃ©cessaire
            reindex_result = vector_index_service.reindex_if_needed()
            
            # 3. Optimiser l'index existant
            optimization_result = vector_index_service.optimize_existing_index()
            
            # 4. VÃ©rifier la santÃ© de l'index
            health_check = vector_index_service.get_index_health()
            
            return {
                'performance_analysis': performance_analysis,
                'reindex_check': reindex_result,
                'optimization': optimization_result,
                'health_check': health_check
            }
            
        except Exception as e:
            logger.error(f"Erreur optimisation index: {e}")
            return {'error': str(e)}
    
    def _optimize_embeddings(self) -> Dict[str, Any]:
        """Optimise le service d'embeddings"""
        try:
            # 1. VÃ©rifier la configuration du modÃ¨le
            model_info = embedding_service.get_model_info()
            
            # 2. Nettoyer le cache des embeddings si nÃ©cessaire
            cache_clear_result = embedding_service.clear_cache()
            
            # 3. Valider quelques embeddings existants
            validation_results = []
            sample_docs = DocumentEmbedding.objects.all()[:5]
            
            for doc in sample_docs:
                if doc.embedding:
                    is_valid = embedding_service.validate_embedding(doc.embedding)
                    validation_results.append({
                        'doc_id': doc.id,
                        'is_valid': is_valid,
                        'dimension': len(doc.embedding) if doc.embedding else 0
                    })
            
            # 4. Obtenir les statistiques du cache
            cache_stats = embedding_service.get_cache_stats()
            
            return {
                'model_info': model_info,
                'cache_clear': cache_clear_result,
                'validation_results': validation_results,
                'cache_stats': cache_stats
            }
            
        except Exception as e:
            logger.error(f"Erreur optimisation embeddings: {e}")
            return {'error': str(e)}
    
    def _optimize_monitoring(self) -> Dict[str, Any]:
        """Optimise le systÃ¨me de monitoring"""
        try:
            # 1. Collecter les mÃ©triques actuelles
            current_metrics = advanced_monitoring_service.collect_system_metrics()
            
            # 2. VÃ©rifier la santÃ© du systÃ¨me
            health_check = advanced_monitoring_service.check_system_health()
            
            # 3. Nettoyer les anciennes donnÃ©es
            cleanup_result = advanced_monitoring_service.clear_old_data(days=7)
            
            # 4. GÃ©nÃ©rer un rapport de performance
            performance_report = advanced_monitoring_service.get_performance_report(hours=24)
            
            return {
                'current_metrics': current_metrics,
                'health_check': health_check,
                'cleanup': cleanup_result,
                'performance_report': performance_report
            }
            
        except Exception as e:
            logger.error(f"Erreur optimisation monitoring: {e}")
            return {'error': str(e)}
    
    def _intelligent_warmup(self) -> Dict[str, Any]:
        """PrÃ©chauffage intelligent du systÃ¨me"""
        try:
            warmup_results = {}
            
            # 1. PrÃ©chauffer les embeddings frÃ©quents
            frequent_queries = [
                "Quelle est la date d'inauguration de la SAR ?",
                "Quelle est la capacitÃ© de la SAR ?",
                "Quels sont les produits de la SAR ?",
                "Qui est le prÃ©sident de la SAR ?",
                "OÃ¹ se trouve la SAR ?",
                "Quelle est l'histoire de la SAR ?",
                "Quels sont les clients de la SAR ?",
                "Comment fonctionne la SAR ?"
            ]
            
            embedding_warmup_count = 0
            for query in frequent_queries:
                if not advanced_cache_service.get_cached_embedding(query):
                    try:
                        embedding = embedding_service.generate_embedding(query)
                        advanced_cache_service.cache_embedding(query, embedding)
                        embedding_warmup_count += 1
                    except Exception as e:
                        logger.warning(f"Erreur warmup embedding pour '{query}': {e}")
            
            warmup_results['embeddings_warmed'] = embedding_warmup_count
            
            # 2. PrÃ©chauffer les recherches frÃ©quentes
            search_warmup_count = 0
            for query in frequent_queries:
                try:
                    results = vector_search_service.search_similar(query, limit=3, threshold=0.7)
                    if results:
                        # Mettre en cache les rÃ©sultats
                        cache_data = []
                        for doc in results:
                            cache_data.append({
                                'id': doc.id,
                                'content': doc.content_text,
                                'metadata': doc.metadata,
                                'similarity': getattr(doc, 'similarity', 0.0)
                            })
                        advanced_cache_service.cache_search(query, 3, 0.7, cache_data)
                        search_warmup_count += 1
                except Exception as e:
                    logger.warning(f"Erreur warmup search pour '{query}': {e}")
            
            warmup_results['searches_warmed'] = search_warmup_count
            
            # 3. PrÃ©chauffer le monitoring
            try:
                advanced_monitoring_service.collect_system_metrics()
                warmup_results['monitoring_warmed'] = True
            except Exception as e:
                logger.warning(f"Erreur warmup monitoring: {e}")
                warmup_results['monitoring_warmed'] = False
            
            return warmup_results
            
        except Exception as e:
            logger.error(f"Erreur intelligent warmup: {e}")
            return {'error': str(e)}
    
    def _validate_performance(self) -> Dict[str, Any]:
        """Valide les performances aprÃ¨s optimisation"""
        try:
            validation_results = {}
            
            # 1. Test de performance des embeddings
            start_time = time.time()
            test_embedding = embedding_service.generate_embedding("Test de performance")
            embedding_time = (time.time() - start_time) * 1000
            validation_results['embedding_time_ms'] = round(embedding_time, 2)
            
            # 2. Test de performance de recherche
            start_time = time.time()
            search_results = vector_search_service.search_similar(
                "Test de performance de recherche", 
                limit=3, 
                threshold=0.7
            )
            search_time = (time.time() - start_time) * 1000
            validation_results['search_time_ms'] = round(search_time, 2)
            validation_results['search_results_count'] = len(search_results)
            
            # 3. Test de performance du cache
            cache_stats = advanced_cache_service.get_cache_stats()
            validation_results['cache_stats'] = cache_stats
            
            # 4. Test de performance du monitoring
            monitoring_metrics = advanced_monitoring_service.collect_system_metrics()
            validation_results['monitoring_metrics'] = monitoring_metrics
            
            # 5. Calculer le score de performance global
            performance_score = self._calculate_performance_score(validation_results)
            validation_results['performance_score'] = performance_score
            
            return validation_results
            
        except Exception as e:
            logger.error(f"Erreur validation performance: {e}")
            return {'error': str(e)}
    
    def _calculate_performance_score(self, validation_results: Dict[str, Any]) -> int:
        """Calcule un score de performance global"""
        try:
            score = 100
            
            # PÃ©nalitÃ©s basÃ©es sur les temps de rÃ©ponse
            if validation_results.get('embedding_time_ms', 0) > 100:
                score -= 20
            elif validation_results.get('embedding_time_ms', 0) > 50:
                score -= 10
            
            if validation_results.get('search_time_ms', 0) > 500:
                score -= 30
            elif validation_results.get('search_time_ms', 0) > 200:
                score -= 15
            
            # Bonus pour le cache
            cache_stats = validation_results.get('cache_stats', {})
            if cache_stats.get('status') == 'active':
                hit_rate = cache_stats.get('hit_rate', 0)
                if hit_rate > 80:
                    score += 10
                elif hit_rate > 60:
                    score += 5
            
            return max(0, min(100, score))
            
        except Exception:
            return 50  # Score par dÃ©faut en cas d'erreur
    
    def _record_optimization(self, results: Dict[str, Any], duration: float) -> None:
        """Enregistre les rÃ©sultats de l'optimisation"""
        try:
            optimization_record = {
                'timestamp': timezone.now().isoformat(),
                'duration_seconds': duration,
                'results': results,
                'success': results.get('success', False)
            }
            
            self.performance_history.append(optimization_record)
            
            # Garder seulement les 100 derniÃ¨res optimisations
            if len(self.performance_history) > 100:
                self.performance_history = self.performance_history[-100:]
                
        except Exception as e:
            logger.error(f"Erreur enregistrement optimisation: {e}")
    
    def get_optimization_status(self) -> Dict[str, Any]:
        """Retourne le statut actuel de l'optimisation"""
        try:
            # VÃ©rifier la santÃ© de tous les services
            cache_health = advanced_cache_service.get_cache_health()
            index_health = vector_index_service.get_index_health()
            monitoring_health = advanced_monitoring_service.check_system_health()
            
            # Calculer un score de santÃ© global
            health_scores = []
            if cache_health.get('status') == 'excellent':
                health_scores.append(100)
            elif cache_health.get('status') == 'good':
                health_scores.append(80)
            elif cache_health.get('status') == 'warning':
                health_scores.append(60)
            else:
                health_scores.append(40)
            
            if index_health.get('status') == 'healthy':
                health_scores.append(100)
            elif index_health.get('status') == 'warning':
                health_scores.append(70)
            else:
                health_scores.append(50)
            
            if monitoring_health.get('status') == 'excellent':
                health_scores.append(100)
            elif monitoring_health.get('status') == 'good':
                health_scores.append(80)
            else:
                health_scores.append(60)
            
            overall_health_score = sum(health_scores) / len(health_scores) if health_scores else 0
            
            return {
                'timestamp': timezone.now().isoformat(),
                'overall_health_score': round(overall_health_score, 2),
                'cache_health': cache_health,
                'index_health': index_health,
                'monitoring_health': monitoring_health,
                'optimization_history_count': len(self.performance_history),
                'last_optimization': self.performance_history[-1] if self.performance_history else None
            }
            
        except Exception as e:
            logger.error(f"Erreur statut optimisation: {e}")
            return {
                'error': str(e),
                'timestamp': timezone.now().isoformat()
            }
    
    def schedule_automatic_optimization(self) -> Dict[str, Any]:
        """Planifie une optimisation automatique"""
        try:
            from datetime import timedelta
            
            next_optimization = timezone.now() + timedelta(
                hours=self.optimization_config['auto_optimization']['interval_hours']
            )
            
            self.optimization_schedule.append({
                'scheduled_time': next_optimization.isoformat(),
                'type': 'automatic',
                'status': 'scheduled'
            })
            
            return {
                'success': True,
                'scheduled_time': next_optimization.isoformat(),
                'interval_hours': self.optimization_config['auto_optimization']['interval_hours']
            }
            
        except Exception as e:
            logger.error(f"Erreur planification optimisation: {e}")
            return {'error': str(e)}

# Instance globale
intelligent_optimization_service = IntelligentOptimizationService()
